---
title: "EldersAIR initial PM data work"
author: "Ethan Walker"
date: "Started 12 Feb 2020, Updated 21 Aug 2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE}
library(tidyverse)
library(readxl)
library(naniar)
library(lubridate)
library(zoo)
library(knitr)
jv_palette <- c("#330099","#CC0066","#FF6633", 
                 "#0099CC", "#FF9900","#CC6633",
                  "#FF3366", "#33CC99", "#33999")
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", 
               "#0072B2", "#D55E00", "#CC79A7")
```

```{r}
file_path <- c("C:/Users/ethan.walker/Box/Ethan Walker UM/R/EldersAIR/")
```


# Load, format, and save Dustrak log files
```{r}
np_dustrak_initial <- read_xlsx(paste0(file_path, "Input/NP/dusttrack.xlsx"),
                                skip = 1, na = c("", "NULL"),
                                col_names = c("home_winter_id", "dtid", "file_name",
                                              "dt_cleaned", "dt_zeroed", "pm_comments",
                                              "start_date", "start_time",
                                              "stop_date", "stop_time",
                                              "sample_interval", "sample_obs",
                                              "sample_ave", "sample_min", "sample_max",
                                              "sampling_visit", "dt_qaqc"),
                                col_types = c("text", "text", "text",
                                              "text", "text", "text",
                                              "date", "date",
                                              "date", "date",
                                              "text", "numeric",
                                              "numeric", "numeric", "numeric",
                                              "text", "text")) %>% 
  # rename variables
  separate(start_time, c("trash1", "start_time_pm"), sep = " ", remove = FALSE) %>% 
  separate(stop_time, c("trash1", "stop_time_pm"), sep = " ", remove = FALSE) %>% 
  mutate(home_winter_id = as.factor(home_winter_id),
         dtid = as.factor(dtid),
         start_date_pm = ymd(start_date),
         start_time_pm = as.character(start_time_pm),
         stop_date_pm = ymd(stop_date),
         stop_time_pm = as.character(stop_time_pm),
         sample_obs = as.numeric(sample_obs),
         sample_ave = as.numeric(sample_ave),
         sample_min = as.numeric(sample_min),
         sample_max = as.numeric(sample_max),
         sampling_visit = as.factor(sampling_visit),
         area = "NPT") %>% 
  select(home_winter_id, area, dtid, sampling_visit, start_date_pm, start_time_pm,
         stop_date_pm, stop_time_pm, sample_interval, sample_obs, sample_ave, sample_min,
         sample_max, pm_comments, file_name) %>% 
  arrange(home_winter_id)


nn_dustrak_initial <- read_xlsx(paste0(file_path, "Input/NN/dusttrack.xlsx"),
                                skip = 1, na = c("", "NULL"),
                                col_names = c("home_winter_id", "dtid", "file_name",
                                              "dt_cleaned", "dt_zeroed", "pm_comments",
                                              "start_date", "start_time",
                                              "stop_date", "stop_time",
                                              "sample_interval", "sample_obs",
                                              "sample_ave", "sample_min", "sample_max",
                                              "sampling_visit", "dt_qaqc"),
                                col_types = c("text", "text", "text",
                                              "text", "text", "text",
                                              "date", "date",
                                              "date", "date",
                                              "text", "numeric",
                                              "numeric", "numeric", "numeric",
                                              "text", "text")) %>% 
  # rename variables
  separate(start_time, c("trash1", "start_time_pm"), sep = " ", remove = FALSE) %>% 
  separate(stop_time, c("trash1", "stop_time_pm"), sep = " ", remove = FALSE) %>% 
  mutate(home_winter_id = as.factor(home_winter_id),
         dtid = as.factor(dtid),
         start_date_pm = ymd(start_date),
         start_time_pm = as.character(start_time_pm),
         stop_date_pm = ymd(stop_date),
         stop_time_pm = as.character(stop_time_pm),
         sample_obs = as.numeric(sample_obs),
         sample_ave = as.numeric(sample_ave),
         sample_min = as.numeric(sample_min),
         sample_max = as.numeric(sample_max),
         sampling_visit = as.factor(sampling_visit),
         area = "NN") %>% 
  select(home_winter_id, area, dtid, sampling_visit, start_date_pm, start_time_pm,
         stop_date_pm, stop_time_pm, sample_interval, sample_obs, sample_ave, sample_min,
         sample_max, pm_comments, file_name) %>% 
  arrange(home_winter_id)


elders_dustrak_log <- rbind(np_dustrak_initial, nn_dustrak_initial)


elders_ids_linked <- read_rds(paste0(file_path, "Output/elders_ids_linked.rds")) 


elders_dustrak_log_new <- elders_dustrak_log %>% 
  left_join(elders_ids_linked, by = c("area", "home_winter_id")) %>% 
  filter(!is.na(home)) %>% 
  mutate(file_name = gsub(c("uploads/"), "", file_name),
         file_name = gsub(c(".tkp"), "", file_name),
         file_name = gsub(c(".txt"), "", file_name),
         file_name = gsub(c(".TKP"), "", file_name),
         file_name = gsub(c(".csv"), "", file_name),
         file_name = gsub(c(".xlsx"), "", file_name)) %>% 
  select(area, home, home_id_num, home_winter_id, winter_id, sampling_visit, treatment,
         adult_id_num, adult_id_char, dtid:file_name) %>% 
  arrange(home, winter_id)

summary(elders_dustrak_log_new)

write_rds(elders_dustrak_log_new, paste0(file_path, "Output/elders_dustrak_log.rds"))
```


# Initial load, format, and save EldersAIR DustTrak (PM) data
## Files were downloaded from Box: NoonanGroupData > EldersAIR
```{r}
##### Read in dusttrack .txt files #####


### NN ###
# List files
list_text_files <- list.files(paste0(file_path, "Input/NN/nn_dustrak/text"))

# Set working directory and load files in list; extract file name and add as column
## run next 4 lines together
setwd(paste0(file_path, "Input/NN/nn_dustrak/text")) # set new working directory
initial_data = tibble(file_name = list_text_files) %>% # use list of files from above
  mutate(save_data = lapply(file_name, read_delim, delim = " ", skip = 28)) %>%
  unnest(save_data)


# Format combined file from above; combine with other PM data below
nn_pm_text_space <- initial_data %>% 
  filter(is.na(`MM/dd/yyyy,hh:mm:ss,mg/m^3`)) %>% 
  mutate(date_pm = mdy(`MM/dd/yyyy`),
         time_pm = as.character(`hh:mm:ss`),
         pm = as.numeric(`mg/m^3`),
         area = "NN",
         file_type = "text") %>% 
  unite("datetime", c("date_pm", "time_pm"), sep = " ", remove = FALSE) %>% 
  mutate(datetime_pm = ymd_hms(datetime)) %>% 
  select(area, datetime_pm, date_pm, time_pm, pm, file_type, file_name) %>% 
  arrange(area, file_name, datetime_pm)



# Set working directory and load files in list; extract file name and add as column
## run next 4 lines together
setwd(paste0(file_path, "Input/NN/nn_dustrak/text")) # set new working directory
initial_data = tibble(file_name = list_text_files) %>% # use list of files from above
  mutate(save_data = lapply(file_name, read_delim, delim = ",", skip = 28)) %>%
  unnest(save_data)


# Format combined file from above; combine with other PM data below
nn_pm_text_comma <- initial_data %>% 
  filter(is.na(`MM/dd/yyyy hh:mm:ss mg/m^3`)) %>% 
  mutate(date_pm = mdy(`MM/dd/yyyy`),
         time_pm = as.character(`hh:mm:ss`),
         pm = as.numeric(`mg/m^3`),
         area = "NN",
         file_type = "text") %>% 
  unite("datetime", c("date_pm", "time_pm"), sep = " ", remove = FALSE) %>% 
  mutate(datetime_pm = ymd_hms(datetime)) %>% 
  select(area, datetime_pm, date_pm, time_pm, pm, file_type, file_name) %>% 
  arrange(area, file_name, datetime_pm)



### NP ###
# List files
list_text_files <- list.files(paste0(file_path, "Input/NP/np_dustrak/text"))

# Set working directory and load files in list; extract file name and add as column
## run next 4 lines together
setwd(paste0(file_path, "Input/NP/np_dustrak/text")) # set new working directory
initial_data = tibble(file_name = list_text_files) %>% # use list of files from above
  mutate(save_data = lapply(file_name, read_delim, delim = ",", skip = 29,
                            col_names = c("date", "time", "pm"))) %>%
  unnest(save_data)


# Format combined file from above; combine with other PM data below
np_pm_text_comma <- initial_data %>% 
  mutate(date_pm = mdy(date),
         time_pm = as.character(time),
         pm = as.numeric(pm),
         area = "NPT",
         file_type = "text") %>% 
  unite("datetime", c("date_pm", "time_pm"), sep = " ", remove = FALSE) %>% 
  mutate(datetime_pm = ymd_hms(datetime)) %>% 
  select(area, datetime_pm, date_pm, time_pm, pm, file_type, file_name) %>% 
  arrange(area, file_name, datetime_pm)




##### Read in dusttrack .csv files #####


### NN ###
# List files
list_csv_files <- list.files(paste0(file_path, "Input/NN/nn_dustrak/csv"))

# Set working directory and load files in list; extract file name and add as column
## run next 4 lines together
setwd(paste0(file_path, "Input/NN/nn_dustrak/csv")) # set new working directory
initial_data = tibble(file_name = list_csv_files) %>% # use list of files from above
  mutate(save_data = lapply(file_name, read_csv)) %>%
  unnest(save_data)

# Format combined file from above; combine with other PM data below
nn_pm_csv <- initial_data %>% 
  mutate(trash1 = `Instrument Name`,
         trash2 = `DustTrak II`) %>% 
  select(file_name, trash1, trash2) %>% 
  group_by(file_name) %>% 
  mutate(date = if_else(trash1 == "Test Start Date", trash2,"NA"),
         time = if_else(trash1 == "Test Start Time", trash2,"NA")) %>% 
  arrange(date, time) %>% 
  mutate(time = lead(time),
         date = first(date),
         time = first(time),
         elapsed_time = as.numeric(trash1)) %>% 
  filter(!is.na(elapsed_time)) %>% 
  #separate(time, c("time", "trash3"), sep = " ") %>% 
  unite(datetime, c("date", "time"), sep = " ") %>% 
  mutate(pm = as.numeric(trash2),
         datetime = mdy_hms(datetime),
         datetime_pm = datetime + seconds(elapsed_time)) %>% 
  separate(datetime_pm, c("date", "time_pm"), sep = " ", remove = FALSE) %>% 
  mutate(date_pm = ymd(date),
         area = "NN",
         file_type = "csv") %>% 
  ungroup() %>% 
  select(area, datetime_pm, date_pm, time_pm, pm, file_type, file_name) %>% 
  arrange(area, file_name, datetime_pm)


### NP ###
# List files
list_csv_files <- list.files(paste0(file_path, "Input/NP/np_dustrak/csv"))

# Set working directory and load files in list; extract file name and add as column
## run next 4 lines together
setwd(paste0(file_path, "Input/NP/np_dustrak/csv")) # set new working directory
initial_data = tibble(file_name = list_csv_files) %>% # use list of files from above
  mutate(save_data = lapply(file_name, read_csv)) %>%
  unnest(save_data)

# Format combined file from above; combine with other PM data below
np_pm_csv <- initial_data %>% 
  mutate(trash1 = `Instrument Name`,
         trash2 = `DustTrak II`) %>% 
  select(file_name, trash1, trash2) %>% 
  group_by(file_name) %>% 
  mutate(date = if_else(trash1 == "Test Start Date", trash2,"NA"),
         time = if_else(trash1 == "Test Start Time", trash2,"NA")) %>% 
  arrange(date, time) %>% 
  mutate(time = lead(time),
         date = first(date),
         time = first(time),
         elapsed_time = as.numeric(trash1)) %>% 
  filter(!is.na(elapsed_time)) %>% 
  #separate(time, c("time", "trash3"), sep = " ") %>% 
  unite(datetime, c("date", "time"), sep = " ") %>% 
  mutate(pm = as.numeric(trash2),
         datetime = mdy_hms(datetime),
         datetime_pm = datetime + seconds(elapsed_time)) %>% 
  separate(datetime_pm, c("date", "time_pm"), sep = " ", remove = FALSE) %>% 
  mutate(date_pm = ymd(date),
         area = "NPT",
         file_type = "csv") %>% 
  ungroup() %>% 
  select(area, datetime_pm, date_pm, time_pm, pm, file_type, file_name) %>% 
  arrange(area, file_name, datetime_pm)




##### Bind files from above #####
elders_pm <- rbind(nn_pm_csv, nn_pm_text_comma, nn_pm_text_space,
                   np_pm_csv, np_pm_text_comma) %>% 
  arrange(area, file_name, datetime_pm) %>% 
  ungroup()

# Save pm dataset as RDS 
write_rds(elders_pm, paste0(file_path, "Output/elders_pm_full_raw.rds"))
```

# Initial cleaning steps
## Remember to add correction factor
```{r}
elders_pm_full_raw <- read_rds(paste0(file_path, "Output/elders_pm_full_raw.rds")) %>% 
  mutate(file_name = gsub(c(".txt"), "", file_name),
         file_name = gsub(c(".csv"), "", file_name)) 
  
elders_dustrak_log <- read_rds(paste0(file_path, "Output/elders_dustrak_log.rds")) %>% 
  arrange(home, winter_id, sampling_visit)  %>% 
  select(-adult_id_char, -adult_id_num) %>% 
  distinct(file_name, .keep_all = TRUE)


elders_pm_new <- elders_pm_full_raw %>%  
  #filter(area == "AK") %>% 
  # apply correction factor to pm and change to ug
  mutate(pm = pm/1.65,
         pm = pm*1000) %>% 
  mutate(pm = as.numeric(pm),
         day_of_week = weekdays(date_pm)) %>% 
  arrange(area, file_name, date_pm) %>%
  left_join(elders_dustrak_log, by = c("area", "file_name")) %>% 
  filter(!is.na(home)) %>% 
  arrange(area, home, datetime_pm)


elders_pm_new2 <- elders_pm_new %>%   
  group_by(area, home, winter_id, sampling_visit) %>% 
  # new variables summarizing pm2.5 within each home
  mutate(pm_total_observations = n(),
         # new datetime values to calculate sampling interval
         first_datetime = first(datetime_pm),
         last_datetime = last(datetime_pm),
         first_datetime = ymd_hms(first_datetime),
         last_datetime = ymd_hms(last_datetime),
         diff_datetime = interval(first_datetime, last_datetime),
         # total sampling interval, based on first and last datetimes
         pm_sample_interval = diff_datetime/86400,
         # expected number of observations with the sampling interval
         expected_obs = pm_sample_interval*24*60,
         # difference between actual and expected observations
         actual_vs_expected_diff = pm_total_observations - expected_obs,
         # indicator variable if actual vs expected obs > 10 or greater
         actual_vs_expected = if_else(actual_vs_expected_diff < 10 &
                                      actual_vs_expected_diff > -10, 1, 0),
         pm_mean = mean(pm),
         # breaking sampling period into days
         obs = row_number(),
         sampling_day = if_else(obs < 1441, 1, 0),
         sampling_day = if_else(obs < 2881 & obs > 1440, 2, sampling_day),
         sampling_day = if_else(obs < 4321 & obs > 2880, 3, sampling_day)) %>%
  # calculate pm means for each sampling day
  group_by(area, home, sampling_day) %>% 
  mutate(pm_mean_daily = mean(pm),
         pm_sampling_day = sampling_day) %>%
  unite(start_datetime_pm, c("start_date_pm", "start_time_pm"), sep = " ", remove = FALSE) %>% 
  mutate(start_datetime_pm = ymd_hms(start_datetime_pm),
         pm_start_diff = interval(first_datetime, start_datetime_pm),
         pm_start_diff_hrs = pm_start_diff/3600) %>% 
  ungroup() %>% 
  select(-obs, -sampling_day) %>% 
  arrange(area, home, sampling_visit) 
# write_rds(elders_pm_new2, paste0(file_path, "Output/elders_pm_new.rds"))


pm_summary <- elders_pm_new2 %>% 
  group_by(area, home, winter_id, sampling_visit) %>%
  distinct(sampling_visit, .keep_all = TRUE)
# write_csv(pm_summary, paste0(file_path, "Output/elders_pm_summary.csv"))
```


# Check sample start times and PM values
```{r}
# Load data 
file_path <- c("C:/Users/ethan.walker/Box/Ethan Walker UM/R/EldersAIR/")
elders_pm <- read_rds(paste0(file_path, "Output/elders_pm_new.rds"))


# Checking difference between dustrak start datetime and field data log datetime
sample_times <- elders_pm %>% 
  group_by(area, home, home_winter_id, sampling_visit) %>% 
  arrange(datetime_pm) %>% 
  mutate(pm_sd = sd(pm, na.rm = TRUE),
         pm_min = min(pm, na.rm = TRUE),
         pm_med = median(pm, na.rm = TRUE),
         pm_max = max(pm, na.rm = TRUE),
         starttime_diff = (datetime_pm - start_datetime_pm)/60) %>% 
  select(area, home, home_winter_id, winter_id, sampling_visit, datetime_pm, first_datetime,
         start_datetime_pm, last_datetime, pm_total_observations, pm_sample_interval,
         expected_obs, actual_vs_expected_diff, pm_mean, pm_sd, pm_min, pm_med, pm_max,
         starttime_diff) %>% 
  distinct(sampling_visit, .keep_all = TRUE) %>% 
  arrange(area, home, home_winter_id, sampling_visit)
# write_csv(sample_times, paste0(file_path, "Output/pm_sample_times_comparison.csv"))
```


# Histogram for distribution of PM by individual ID
```{r}
# Load data 
file_path <- c("C:/Users/ethan.walker/Box/Ethan Walker UM/R/EldersAIR/")
elders_pm <- read_rds(paste0(file_path, "Output/elders_pm_new.rds"))


histogram_id <- elders_pm %>% 
  filter(home_winter_id == "10" & area == "NN") %>% 
  ggplot() + 
    geom_histogram(aes(pm), bins = 50) +
    theme_classic()
histogram_id
```

# Function to look at PM data across time
```{r}
# Plot PM by datetime to look at trends, gaps, and peaks
pm_time_plot_function <- function(id, location, visit) {
  
pm_time_plot <- elders_pm %>% 
  filter(home_winter_id == id & area == location & sampling_visit == visit) %>% 
  #filter(pm < 30000) %>% 
  arrange(datetime_pm) %>% 
  mutate(pm_sampling_day = as.character(pm_sampling_day),
         day_of_week = factor(day_of_week,
                              levels = c("Sunday", "Monday", "Tuesday", "Wednesday", 
                                         "Thursday", "Friday", "Saturday"))) %>%
  ggplot() + 
    geom_point(aes(datetime_pm, pm, color = day_of_week), size = 1.5) +
    theme_classic() +
    labs(title = id,
         y = expression(paste("PM"[2.5], " (", mu, g/m^3, ")")),
         x = "Datetime",
         color = "Day of week") +
    theme(axis.title.y = element_text(size = 12,
                                      margin = margin(t = 0, r = 20, b = 0, l = 0)),
          axis.title.x = element_text(size = 12),
          axis.text.x = element_blank(),
          axis.text.y = element_text(size = 12, color = "black"),
          axis.line.x = element_line(colour = "black", size = 1), 
          axis.line.y = element_line(colour = "black", size = 1), 
          axis.ticks = element_blank()) +
    scale_color_manual(values = jv_palette)

gaps <<- elders_pm %>% 
  filter(home_winter_id == id & area == location & sampling_visit == visit) %>% 
  mutate(datetime_pm = ymd_hms(datetime_pm),
         datetime_lead = ymd_hms(lead(datetime_pm)),
         datetime_1 = seconds(datetime_pm),
         datetime_2 = seconds(datetime_lead),
         datetime_diff_minutes = as.numeric(datetime_2 - datetime_1)/60,
         datetime_diff_hours = as.numeric(datetime_diff_minutes/60)) %>% 
  arrange(desc(datetime_diff_minutes)) %>% 
  select(day_of_week, pm_sampling_day, datetime_diff_minutes, datetime_diff_hours, 
         datetime_pm, datetime_lead)

pm_desc <<- elders_pm %>% 
  filter(home_winter_id == id & area == location & sampling_visit == visit) %>% 
  arrange(desc(pm)) %>% 
  select(datetime_pm, pm, pm_sampling_day)
pm_time_plot

}
```

# Run function from above to look at results
## Function run for each household to check for odd trends/gaps in the data
## Notes from this process on uploaded to Box:
### EldersAIR > Ethan - data cleaning and analysis > pm_cleaning_summary
```{r}
# Load data 
file_path <- c("C:/Users/ethan.walker/Box/Ethan Walker UM/R/EldersAIR/")
elders_pm <- read_rds(paste0(file_path, "Output/elders_pm_new.rds"))

# Change function input to look at specific home
# Run these 4 lines together
pm_time_plot_function(location = "NPT", id = "163", visit = 2)
head(gaps, 10)
head(pm_desc, 10)
tail(pm_desc, 10)

# filter data for a single home
check_data <- elders_pm %>% 
  filter(area == "NN" & home_winter_id == "11" & sampling_visit == 1) %>% 
  filter(pm < 0)
```


# Fix PM data after checking odd values and time differences
```{r}
# Load data 
file_path <- c("C:/Users/ethan.walker/Box/Ethan Walker UM/R/EldersAIR/")
elders_pm <- read_rds(paste0(file_path, "Output/elders_pm_new.rds"))

# Load file with data cleaning notes
pm_sample_times_comparison <- read_xlsx(paste0(file_path, "Input/pm_sample_times_comparison_21aug2020.xlsx")) %>% 
  select(area, home, home_winter_id, winter_id, sampling_visit, cleaning_comments, 
         next_steps, sensitivity_analysis) %>% 
  mutate(winter_id = as.factor(winter_id),
         home_winter_id = as.factor(home_winter_id),
         sampling_visit = as.factor(sampling_visit))


elders_pm_new <- elders_pm %>% 
  mutate(pm = if_else(pm > 12000, 999999, pm)) %>% 
  replace_with_na(replace = list(pm = 999999)) %>% 
  # join with file on data cleaning notes - refer to pm_sample_times_comparison file
  left_join(pm_sample_times_comparison, c("area", "home", "home_winter_id", "winter_id", "sampling_visit")) %>% 
  # filter out sampling visits with bad data - refer to pm_sample_times_comparison file
  filter(next_steps != "Do not use due to short run time") %>% 
  filter(next_steps != "Do not use due to high baseline/minimum values") %>% 
  filter(next_steps != "Do not use due to negatives") %>% 
  # replace PM < 1 (lower DustTrak limit) with 0.5 (lower limit / 2) 
  # only doing this for files with a few negative values
  mutate(pm = if_else(pm < 1, 0.5, pm)) %>% 
  # fix files with incorrect datetimes 
  mutate(datetime_pm = ymd_hms(datetime_pm),
         pm_datetime_new = if_else(next_steps == "Subtract 1 hour from datetime", 
                                   datetime_pm - 3600, datetime_pm),
         pm_datetime_new = if_else(next_steps == "Add 1 hour to datetime", 
                                   datetime_pm + 3600, pm_datetime_new),
         pm_datetime_new = if_else(next_steps == "Add 1 day to datetime", 
                                   datetime_pm + 86400, pm_datetime_new),
         pm_datetime_new = if_else(next_steps == "Add 2 hours to datetime", 
                                   datetime_pm + 7200, pm_datetime_new),
         pm_datetime_new = if_else(next_steps == "Add 174970 hours to datetime", 
                                   datetime_pm + 629892000, pm_datetime_new),
         pm_datetime_new = if_else(next_steps == "Subtract 2 hours from datetime", 
                                   datetime_pm - 7200, pm_datetime_new),
         pm_datetime_new = if_else(next_steps == "Subtract 4 hours from datetime", 
                                   datetime_pm - 14400, pm_datetime_new),
         pm_datetime_new = if_else(next_steps == "Subtract 676 hours from datetime", 
                                   datetime_pm - 2433600, pm_datetime_new),
         pm_datetime_new = if_else(next_steps == "Subtract 7.75 hours from datetime", 
                                   datetime_pm - 27900, pm_datetime_new),
         pm_datetime_new = if_else(next_steps == "Subtract 78 hours from datetime", 
                                   datetime_pm - 280800, pm_datetime_new)) %>% 
  # filter(next_steps == "Subtract 78 hours from datetime")
  arrange(area, home, winter_id, sampling_visit, pm_datetime_new) %>% 
  group_by(area, home, winter_id) %>% 
  mutate(pm_mean_winter = mean(pm, na.rm = TRUE)) %>% 
  group_by(area, home, winter_id, sampling_visit) %>% 
  mutate(pm_mean_visit = mean(pm, na.rm = TRUE)) %>%
  group_by(area, home, winter_id, sampling_visit, pm_sampling_day) %>% 
  mutate(pm_mean_daily = mean(pm, na.rm = TRUE),
         day_of_week = weekdays(pm_datetime_new)) %>%
  ungroup() %>% 
  mutate(sample_interval_days = pm_sample_interval) %>% 
  select(area, home, home_id_num, home_winter_id, winter_id, sampling_visit, 
         pm_sampling_day, pm_datetime_new, pm_sample_interval, pm, pm_mean_winter, 
         pm_mean_visit, pm_mean_daily, day_of_week, treatment, dtid, sample_obs,
         pm_comments) %>% 
  arrange(area, home, winter_id, sampling_visit, pm_datetime_new)


write_rds(elders_pm_new, paste0(file_path, "Output/elders_pm_clean.rds"))
```

